* some design questions to be answered:

1. the object language. can be either stlc+y (finitary PCF), or equivalently HORS, or, using the transfer theorem, have it MSOL just like the type language.
2. MSOL can be augmented with a fragment of counting FOL and remain decidable, while giving the possibility to compare (and add) cardinalities of sets ([2]). need to see how it can fit.
3. need to decide whether MSOL will be used as type language directly, or, an automaton-based typesystem.
//4. need a compositional typesystem (e.g. [3], [9])
5. how can tau support multiple logics?
	- a nomic game may take into a consideration additional rules (that may be changed) that speak about "what is truth" and "what amounts as a proof".
	- seems like even prolog compiler can be written in MSOL, but need to think how truths/proofs from another logic may be "imported".
	- can such tau have only a fragment of full MSOL, and recover even more generalized logics via "trusted compilers"?
	- can truth be only something derived from judgements, or we can encode eg "trees of truth"? i think that msol is capable of doing arbitrary Herbrand model reasoning.
6. how good is the idea of using the transfer theorem and be able to use directly only MSOL over [algebraic] graphs? as the terms are regular graphs.
//7. backtracking? ([5])
//8. LISA language (1st order!) [7]

* relevant information:
1. multiparameter tree transducers [16,17], need to see where completeness is lost there. it also presents a limitation of HORS and tries to overcome it
2. algebraic data structures [18,19,20]
3. verification tool [22]

* first implementation tasks:
1. stlc+y
//2. HORS
2. parity automata //, collapsible pushdown automata(, ordered tree pushdown)
3. bohm trees
4. krivine machine
//6. transfer theorem
//7. parity games
//8. logical reflection and effective selection ([6])
//9. economical stlc+y <=> HORS ([1])
//10. stlc+y => CPDA ([1])
5. lattice theoretic model of stlc+y under parity automata (conclusion 1 below)

remarks:
1. very fast algorithms can be found at [8]
2. linear dependent types for pcf [15]

* food for thought:
1. labels -> equivalences -> prefix orders -> trees
2. every infinite path gives rise to peano arithmetic (might be useful for short and fast proofs)
3. one of the big questions: which logics can msol prove to be consistent? can it prove [in]consistency of any herbrand model? cf [8] p. 149 also can do it in translation to constraints fashion (which is preferrable from runtime complexity point of view) similarly to Wand 1987. also self-verifying systems are very appealing http://www.cs.albany.edu/~dew/m/jsl1.pdf
4. how exactly abstract interpretations and higher order model checking are related? can they benefit from each other? what is the preferred underlying representation, should Galois connections be considered as such?
5. higher order tree functions with (generalized) fixpoint (relaxing the complete lattice structure)?

some conclusions:
1. from the above mentioned options, looks like the model theoretic approach is the best available way. it subsums model checking, transfer theorem, and many more. it was first pioneered in [9], also presented in the very good document [10]. a different model was given in [11, 12 chapter 10]. another different one for wmso in [13], and another fragment (omega-blind) in [14].
2. since we prefer the proof search method for various reasons, the order theoretic models can be seen as a subsystem of [5] (which itself a subsystem of second order peano). 

* references:
[1] "Simply typed fixpoint calculus and collapsible pushdown automata" Salvati&Walukiewicz
[2] https://arxiv.org/abs/1505.06622
[3] www.kb.is.s.u-tokyo.ac.jp/~tsukada/papers/effect-arena-long.pdf
[4] "Recursion Schemes and Logical Reflection" Broadbent, Carayol, Ong, Serre
[5] http://www.anupamdas.com/items/CompAxMSOTrees/CompAxMSOTrees.pdf
[6] https://hal.archives-ouvertes.fr/hal-00865682v2/document
[7] https://swt.informatik.uni-freiburg.de/berit/papers/lisa_a_specification_language_based_on_ws_s.pdf
[8] http://www.di.ens.fr/~mauborgn/publi/t.pdf
[9] https://hal.archives-ouvertes.fr/hal-01145494/document
[10] https://hal.archives-ouvertes.fr/tel-01253426/document
[11] https://arxiv.org/pdf/1502.05147.pdf
[12] https://hal.archives-ouvertes.fr/tel-01311150/document
[13] http://drops.dagstuhl.de/opus/volltexte/2016/6551/pdf/LIPIcs-CSL-2016-11.pdf
[14] https://hal.archives-ouvertes.fr/hal-01169352/file/hal-version.pdf
[15] https://arxiv.org/pdf/1104.0193.pdf
[16] https://pdfs.semanticscholar.org/2853/c0152f9c9abb90d4deefe83e968807e48940.pdf
[17] "High Level Tree Transducers and Iterated Pushdown Tree Transducers" Engelfriet&Vogler
[18] http://www.cs.tsukuba.ac.jp/~uhiro/papers/aplas2010cf.pdf
[19] http://www.brics.dk/mona/mona14.pdf
[20] https://www.cs.ox.ac.uk/files/3721/main.pdf
[21] https://www.react.uni-saarland.de/teaching/automata-games-verification-08/lecture-notes.html good explanations about parity automata
[22] http://spinroot.com/spin/whatispin.html

RDF setting:

a kb consists of a set of rdf graphs, each contains rules. every graph can be written as a tree where the root's decendants are the rules, where each rule has two subtrees (premises and consequences) that consist of triples and from here we have the usual tree-term structure. the tree is labeled by two labels: context and uri, to be expressed via two equivalence relations among tree nodes and across graphs. 
we want to be able to assert MSOL properties on this tree. in addition, we'd like to use a tree generator that supports much larger class of MSOL definable trees (yet MSOL decidable), namely, trees generated by higher order recursion schemes. plain rdf graphs seem to be a first order recursion scheme.
we would therefore be interested in incorporating a typesystem into rdf (via the predicate rdf:type or just "a" in short) that speaks about those trees and express MSOL formulas about them. basically we have two kinds of trees to model-check: those who consist of rdf resources (uris), and those who consist of triples (graphs), where obviously the formers are subtrees of the latters.
since on this setting all rdf resources are tree nodes, the typesystem can quantify over sets of such.
a rule is ground if it's given without any premise nor free variables, or if all its premises are ground under certain equivalence (which are actually substitutions but significantly simplified). specifically, the rules themselves determine the allowed substitution together with few more metarules. 
the semantics of an rdf graph is very similar to lambdas' Bohm tree. for a convenient typesystem we'll have to see whether rdf graph entailment is msol expressible.
a proof is a tree with root being the query. a node may have k successors where k is the number of rules, giving rise to WSkS such that the k successors are distinguished from each other. indeed, each rule encapsulate different unification predicates. they consist of expressing whether certain equivalences can be declared without breaking the metarules (of tree structure, equivalence relations and unification). 
