* some design questions to be answered:

1. the object language. can be either stlc+y (finitary PCF), or equivalently HORS, or, using the transfer theorem, have it MSOL just like the type language.
2. MSOL can be augmented with a fragment of counting FOL and remain decidable, while giving the possibility to compare (and add) cardinalities of sets ([2]). need to see how it can fit.
3. need to decide whether MSOL will be used as type language directly, or, an automaton-based typesystem.
//4. need a compositional typesystem (e.g. [3], [9])
4. how can tau support multiple logics?
	- a nomic game may take into a consideration additional rules (that may be changed) that speak about "what is truth" and "what amounts as a proof".
	- seems like even prolog compiler can be written in MSOL, but need to think how truths/proofs from another logic may be "imported".
	- can such tau have only a fragment of full MSOL, and recover even more generalized logics via "trusted compilers"?
	- can truth be only something derived from judgements, or we can encode eg "trees of truth"? i think that msol is capable of doing arbitrary Herbrand model reasoning.
5. how good is the idea of using the transfer theorem [23] and be able to use directly only MSOL over [algebraic] graphs? as the terms are regular graphs.
//7. backtracking? ([5])
//8. LISA language (1st order!) [7]
6. in [24] there's *exact* abstract interpretation approach to Ramsay's typesystem. what are the main differences between it and Salvati&Walukiewicz extended scott model? there's at least one similarity, [24] says "To rectify the situation we describe an additional requirement, which is that the abstract property space at ground kind contains “no junk”, and this leads to exact characterisations at higher-kinds." vs [9]'s "Instead our construction introduces ranks only in higher types." (indeed they extend scott model by adding ranks to higher kinds only)
7. extensions of mso (e.g. [27,29])
8. need to think how logic programming can be decribed as a transition system, especially with constraints-based implementation. [32] presents machine proof for wand(1987) algorithm. it can be a candidate for a level over msol. we could generalize by instead of {spo}=>{spo} have {msol formula} <tranduces to> {msol formula}, where the transduction has to be msol compatible (beyond simply "msol definable"). as subtitutions (courcelle 1998) and evaluation (S&W 2013) are msol compatible, but still need the metalevel flow (e.g. sld resolution).

* relevant information:
1. multiparameter tree transducers [16,17], need to see where completeness is lost there. it also presents a limitation of HORS and tries to overcome it
2. algebraic data structures [18,19,20]
3. verification tool [22]
4. combining different logics: Nelson-Oppen is commonly cited for such

* first implementation tasks:
1. stlc+y
//2. HORS
2. parity automata //, collapsible pushdown automata(, ordered tree pushdown)
3. bohm trees
4. krivine machine
//6. transfer theorem
//7. parity games
//8. logical reflection and effective selection ([6])
//9. economical stlc+y <=> HORS ([1])
//10. stlc+y => CPDA ([1])
5. lattice theoretic model of stlc+y under parity automata (conclusion 1 below)

remarks:
1. very fast algorithms can be found at [8]
2. linear dependent types for pcf [15]

* food for thought:
1. labels -> equivalences -> prefix orders -> trees
2. every infinite path gives rise to peano arithmetic (might be useful for short and fast proofs)
3. one of the big questions: which logics can msol prove to be consistent? can it prove [in]consistency of any herbrand model? cf [8] p. 149 also can do it in translation to constraints fashion (which is preferrable from runtime complexity point of view) similarly to Wand 1987. also self-verifying systems are very appealing http://www.cs.albany.edu/~dew/m/jsl1.pdf
4. how exactly abstract interpretations and higher order model checking are related? can they benefit from each other? what is the preferred underlying representation, should Galois connections be considered as such?
5. higher order tree functions with (generalized) fixpoint (relaxing the complete lattice structure)?
6. what [25] has to do with all of that?
	* "The idea is that such an impasse can be avoided by sharing common subterms along the evaluation process, in order to keep the representation of the output compact, i.e. polynomially related to the number of evaluation steps. But is appropriately managed sharing enough? The answer is positive, at least for certain restricted forms of reduction: the number of steps is already known to be an invariant cost model for weak reduction [BG95, SGM02, DLM08, DLM12] and for head reduction [ADL12]." which affirms that the optimizations in [8] and the ones i developed for sharing trees indeed avoid exponential explosion. krivine machines are about weak head normal form
7. #P problems are also FPT [28]

some conclusions:
1. from the above mentioned options, looks like the model theoretic approach is the best available way. it subsums model checking, transfer theorem, and many more. it was first pioneered in [9], also presented in the very good document [10]. a different model was given in [11, 12 chapter 10]. another different one for wmso in [13], and another fragment (omega-blind) in [14].
2. since we prefer the proof search method for various reasons, the order theoretic models can be seen as a subsystem of [5] (which itself a subsystem of second order peano). 

* references:
[1] "Simply typed fixpoint calculus and collapsible pushdown automata" Salvati&Walukiewicz
[2] https://arxiv.org/abs/1505.06622
[3] www.kb.is.s.u-tokyo.ac.jp/~tsukada/papers/effect-arena-long.pdf
[4] "Recursion Schemes and Logical Reflection" Broadbent, Carayol, Ong, Serre
[5] http://www.anupamdas.com/items/CompAxMSOTrees/CompAxMSOTrees.pdf
[6] https://hal.archives-ouvertes.fr/hal-00865682v2/document
[7] https://swt.informatik.uni-freiburg.de/berit/papers/lisa_a_specification_language_based_on_ws_s.pdf
[8] http://www.di.ens.fr/~mauborgn/publi/t.pdf
[9] https://hal.archives-ouvertes.fr/hal-01145494/document
[10] https://hal.archives-ouvertes.fr/tel-01253426/document
[11] https://arxiv.org/pdf/1502.05147.pdf
[12] https://hal.archives-ouvertes.fr/tel-01311150/document
[13] http://drops.dagstuhl.de/opus/volltexte/2016/6551/pdf/LIPIcs-CSL-2016-11.pdf
[14] https://hal.archives-ouvertes.fr/hal-01169352/file/hal-version.pdf
[15] https://arxiv.org/pdf/1104.0193.pdf
[16] https://pdfs.semanticscholar.org/2853/c0152f9c9abb90d4deefe83e968807e48940.pdf
[17] "High Level Tree Transducers and Iterated Pushdown Tree Transducers" Engelfriet&Vogler
[18] http://www.cs.tsukuba.ac.jp/~uhiro/papers/aplas2010cf.pdf
[19] http://www.brics.dk/mona/mona14.pdf
[20] https://www.cs.ox.ac.uk/files/3721/main.pdf
[21] https://www.react.uni-saarland.de/teaching/automata-games-verification-08/lecture-notes.html good explanations about parity automata
[22] http://spinroot.com/spin/whatispin.html
[23] http://drops.dagstuhl.de/opus/volltexte/2013/4365/pdf/6.pdf
[24] https://www2.warwick.ac.uk/fac/sci/dcs/people/steven_ramsay/dissertation.pdf
[25] https://arxiv.org/pdf/1601.01233.pdf
[26] http://drops.dagstuhl.de/opus/volltexte/2013/4364/pdf/5.pdf
[27] http://drops.dagstuhl.de/opus/volltexte/2015/5430/pdf/27.pdf
[28] http://www.dbai.tuwien.ac.at/proj/tractability/JaklPRW08b.pdf
[29] http://www.math.helsinki.fi/logic/people/hannu.niemisto/MonadicCH.pdf
[30] http://www.dbai.tuwien.ac.at/research/project/tractability/toclGottlobPW10.pdf
[31] https://www.cs.ox.ac.uk/files/1246/bry-rdflog-full.pdf
[32] http://www.cs.uwyo.edu/~jlc/papers/WMM09.pdf

RDF setting:

a kb consists of a set of rdf graphs, each contains rules. every graph can be written as a tree where the root's decendants are the rules, where each rule has two subtrees (premises and consequences) that consist of triples and from here we have the usual tree-term structure. the tree is labeled by two labels: context and uri, to be expressed via two equivalence relations among tree nodes and across graphs. 
we want to be able to assert MSOL properties on this tree. in addition, we'd like to use a tree generator that supports much larger class of MSOL definable trees (yet MSOL decidable), namely, trees generated by higher order recursion schemes. plain rdf graphs seem to be a first order recursion scheme.
we would therefore be interested in incorporating a typesystem into rdf (via the predicate rdf:type or just "a" in short) that speaks about those trees and express MSOL formulas about them. basically we have two kinds of trees to model-check: those who consist of rdf resources (uris), and those who consist of triples (graphs), where obviously the formers are subtrees of the latters.
since on this setting all rdf resources are tree nodes, the typesystem can quantify over sets of such.
a rule is ground if it's given without any premise nor free variables, or if all its premises are ground under certain equivalence (which are actually substitutions but significantly simplified). specifically, the rules themselves determine the allowed substitution together with few more metarules. 
the semantics of an rdf graph is very similar to lambdas' Bohm tree. for a convenient typesystem we'll have to see whether rdf graph entailment is msol expressible. it seems easy on first order setting, but can it be done with higher order recursion scheme? it seems like it's possible with having n+1 order scheme. it's better to do it with msol but ofc stlc+y is as good.
a proof is a tree with root being the query. a node may have k successors where k is the number of rules, giving rise to (W)SkS such that the k successors are distinguished from each other. indeed, each rule encapsulate a different unification predicate. if match occurs, this rules have successors which represent its premises to be grounded, giving another set of successors. so the total number of different successor relations is bounded by the number of heads plus the number of premises. the match predicates consist of expressing whether certain equivalences can be declared without breaking the metarules (of tree structure, equivalence relations and unification). so the proof tree is msol expressible with WSkS and k rules (aside the metarules), each contribute another two levels to the proof tree in every iteration over the leaves. iterating over all possible equivalences (substitutions) is exactly where monadic second order comes in (set variables). if we use SkS rather WSkS, we can even speak about infinitely many variables. this reminds the transfer theorem from [23] which allows infinitely many Y variables but not lambda variables.
enhancing rdf to higher order recursion schemes require the ability for a kb to speak about its own rules, and moreover, to quantify rules (strongly connected to nomic), and to have rules that accept rules as parameters and return rules. an n-order recursion scheme would have rules-over-rules-over-... to height n. an rdf rule can be seen as a graph by its own, as it's essentially a triple with log:implies and two graph identifiers, and a single triple can be seen as a graph by its own. indeed in the rdf-to-tree representation we began with, equivalence can be done among resources and graph nodes as well. an "ordinary" rdf graph is aware only to the lower levels of this tree, namely, the triples themselves, but not to the upper levels (graphs and rules). we can therefore go up from a definition of graph to a definition of the whole kb, and let the kb itself be aware to it's whole structure. specifically it means that the whole kb tree described above will be accessed from some enhanced syntax, or using builtins. then, we are able to speak about rules directly, or even specify rules implicitly, namely, we got higher order recursion scheme.
as in [23], stlc+y representing a bohm tree can itself be a regular tree, and even finite. only the bohm tree can be infinite and irregular on this setting. it's interesting that our description of msol-definable resolution does not go through the bohm tree, namely the semantics of the rdf kb, but performs the backtracking on the syntactic level only. reasoning over graphs' bohm trees would be another feature, much more powerful than offered in total languages where the bohm tree is always finite, and here is not even msol expressible (yet msol decidable) as it's always context-sensitive. but one could argue that we still lose nothing by keeping it msol definable graphs: the transfer theorem show that properties of bohm trees are properties of regular term graphs. so bohm trees can be reasoned over but in a way that does not essentially increase the expressibility of such enhanced rdf graphs. in fact, by adding more axioms for internal use (e.g. PA2), the transfer itself may be performed by means of proof search.

a set of rdf quads is nothing but a way to define labelled graphs. an rdf kb+query is a tree grammar as it represents the sets of all valid proof trees. the proof tree is very closely related to bohm trees, and indeed logic programming is about inference being beta reduction. if P(x)=>Q(x) is a logic program clause, where P,Q are some predicates and (boldface) x is a tuple of variables, then we can write it as a recursion scheme Q(x)=P(x) (we flip the sides since under backtracking semantics of logic programs, Q calls P). it is a 1st order recursion scheme if we name all rules (or taking the predicate as the name in case we disallow predvars), and call all of them in every predicate. this (hors) seem to be a more suitable representation than stlc+y (yet they're equivalent as proved recently [26]) for logic programs. 

the monadic datalog parallel [30] might give plenty of ideas for rdf, also [31] shows that this solves some puzzles with blank nodes.
